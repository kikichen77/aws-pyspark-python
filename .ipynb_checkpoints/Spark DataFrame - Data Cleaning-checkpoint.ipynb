{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame - Data Cleaning\n",
    "There are three options when dealing with missing data: \n",
    "1. Changing the data to null\n",
    "2. Drop the data point (or entire row)\n",
    "3. Fill it in with a different value\n",
    "\n",
    "These points are dependent on your requirements. \n",
    "\n",
    "Objective: Let's explore our options when it comes to cleaning a basic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/03 04:41:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/03 04:41:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('missing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+------+------+------+-----+-----+-----------+----+-----+----+------+------+\n",
      "| id|index|  age|gender|height|weight|ap_hi|ap_lo|cholesterol|gluc|smoke|alco|active|cardio|\n",
      "+---+-----+-----+------+------+------+-----+-----+-----------+----+-----+----+------+------+\n",
      "|  0|    0|18393|     2|   168|  62.0|  110|   80|          1|   1|    0|   0|     1|     0|\n",
      "|  1|    1|20228|     1|   156|  85.0|  140|   90|          3|   1|    0|   0|     1|     1|\n",
      "|  2|    2|18857|     1|   165|  64.0|  130|   70|          3|   1|    0|   0|     0|     1|\n",
      "|  3|    3|17623|     2|   169|  82.0|  150|  100|          1|   1|    0|   0|     1|     1|\n",
      "|  4|    4|17474|     1|   156|  56.0|  100|   60|          1|   1|    0|   0|     0|     0|\n",
      "|  8|    5|21914|     1|   151|  67.0|  120|   80|          2|   2|    0|   0|     0|     0|\n",
      "|  9|    6|22113|     1|   157|  93.0|  130|   80|          3|   1|    0|   0|     1|     0|\n",
      "| 12|    7|22584|     2|   178|  95.0|  130|   90|          3|   3|    0|   0|     1|     1|\n",
      "| 13|    8|17668|     1|   158|  71.0|  110|   70|          1|   1|    0|   0|     1|     0|\n",
      "| 14|    9|19834|     1|   164|  68.0|  110|   60|          1|   1|    0|   0|     0|     0|\n",
      "| 15|   10|22530|     1|   169|  80.0|  120|   80|          1|   1|    0|   0|     1|     0|\n",
      "| 16|   11|18815|     2|   173|  60.0|  120|   80|          1|   1|    0|   0|     1|     0|\n",
      "| 18|   12|14791|     2|   165|  60.0|  120|   80|          1|   1|    0|   0|     0|     0|\n",
      "| 21|   13|19809|     1|   158|  78.0|  110|   70|          1|   1|    0|   0|     1|     0|\n",
      "| 23|   14|14532|     2|   181|  95.0|  130|   90|          1|   1|    1|   1|     1|     0|\n",
      "| 24|   15|16782|     2|   172| 112.0|  120|   80|          1|   1|    0|   0|     0|     1|\n",
      "| 25|   16|21296|     1|   170|  75.0|  130|   70|          1|   1|    0|   0|     0|     0|\n",
      "| 27|   17|16747|     1|   158|  52.0|  110|   70|          1|   3|    0|   0|     1|     0|\n",
      "| 28|   18|17482|     1|   154|  68.0|  100|   70|          1|   1|    0|   0|     0|     0|\n",
      "| 29|   19|21755|     2|   162|  56.0|  120|   70|          1|   1|    1|   0|     1|     0|\n",
      "+---+-----+-----+------+------+------+-----+-----+-----------+----+-----+----+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing data which has a header. Schema is automatically configured.\n",
    "df = spark.read.csv('modify1.csv', header=True, inferSchema=True)\n",
    "heart_data_situation = spark.read.csv('heart-data-situation.csv', header=True, inferSchema=True)\n",
    "\n",
    "merged_df = df.join(heart_data_situation, on=\"id\", how=\"inner\")  \n",
    "\n",
    "# Let's see the data. You'll notice nulls.\n",
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|    Feature|Importance|\n",
      "+-----------+----------+\n",
      "|      ap_hi|      0.53|\n",
      "|      ap_lo|      0.25|\n",
      "|        age|       0.1|\n",
      "|cholesterol|       0.1|\n",
      "|     weight|      0.01|\n",
      "|       gluc|      0.01|\n",
      "|     active|       0.0|\n",
      "|     height|       0.0|\n",
      "|      smoke|       0.0|\n",
      "|       alco|       0.0|\n",
      "|         id|       0.0|\n",
      "|      index|       0.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "feature_cols = ['index', 'id', 'age', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "assembled_data = assembler.transform(merged_df)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"cardio\")\n",
    "model = rf.fit(assembled_data)\n",
    "\n",
    "importances = model.featureImportances.toArray()\n",
    "\n",
    "importances_list = [(feature, float(importance)) for feature, importance in zip(feature_cols, importances)]\n",
    "importance_df = spark.createDataFrame(importances_list, [\"Feature\", \"Importance\"])\n",
    "\n",
    "importance_df = importance_df.orderBy(\"Importance\", ascending=False)\n",
    "\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "importance_df = importance_df.withColumn(\"Importance\", round(importance_df[\"Importance\"], 2))\n",
    "importance_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "      <td>68056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>49961.38948806865</td>\n",
       "      <td>34991.75198366051</td>\n",
       "      <td>19467.796329493358</td>\n",
       "      <td>1.3482132361584578</td>\n",
       "      <td>164.41048548254378</td>\n",
       "      <td>73.72453273774539</td>\n",
       "      <td>126.59862466204302</td>\n",
       "      <td>81.28977606676854</td>\n",
       "      <td>1.3629657928764547</td>\n",
       "      <td>1.2239773128012226</td>\n",
       "      <td>0.08756024450452568</td>\n",
       "      <td>0.05310332667215235</td>\n",
       "      <td>0.8037057717174092</td>\n",
       "      <td>0.4936228987892324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>28838.84055511243</td>\n",
       "      <td>20198.679156291822</td>\n",
       "      <td>2466.8985187743706</td>\n",
       "      <td>0.4764075075852865</td>\n",
       "      <td>7.825610733050222</td>\n",
       "      <td>13.423933068620316</td>\n",
       "      <td>16.517518537922864</td>\n",
       "      <td>9.398565292233743</td>\n",
       "      <td>0.6778290292171032</td>\n",
       "      <td>0.5698690836303668</td>\n",
       "      <td>0.2826563674162662</td>\n",
       "      <td>0.22424116979742773</td>\n",
       "      <td>0.39719657902829786</td>\n",
       "      <td>0.4999630041132576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10798</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>99999</td>\n",
       "      <td>69999</td>\n",
       "      <td>23713</td>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>120.0</td>\n",
       "      <td>220</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 id               index                 age  \\\n",
       "0   count              68056               68056               68056   \n",
       "1    mean  49961.38948806865   34991.75198366051  19467.796329493358   \n",
       "2  stddev  28838.84055511243  20198.679156291822  2466.8985187743706   \n",
       "3     min                  0                   0               10798   \n",
       "4     max              99999               69999               23713   \n",
       "\n",
       "               gender              height              weight  \\\n",
       "0               68056               68056               68056   \n",
       "1  1.3482132361584578  164.41048548254378   73.72453273774539   \n",
       "2  0.4764075075852865   7.825610733050222  13.423933068620316   \n",
       "3                   1                 130                30.0   \n",
       "4                   2                 207               120.0   \n",
       "\n",
       "                ap_hi              ap_lo         cholesterol  \\\n",
       "0               68056              68056               68056   \n",
       "1  126.59862466204302  81.28977606676854  1.3629657928764547   \n",
       "2  16.517518537922864  9.398565292233743  0.6778290292171032   \n",
       "3                  90                 40                   1   \n",
       "4                 220                140                   3   \n",
       "\n",
       "                 gluc                smoke                 alco  \\\n",
       "0               68056                68056                68056   \n",
       "1  1.2239773128012226  0.08756024450452568  0.05310332667215235   \n",
       "2  0.5698690836303668   0.2826563674162662  0.22424116979742773   \n",
       "3                   1                    0                    0   \n",
       "4                   3                    1                    1   \n",
       "\n",
       "                active              cardio  \n",
       "0                68056               68056  \n",
       "1   0.8037057717174092  0.4936228987892324  \n",
       "2  0.39719657902829786  0.4999630041132576  \n",
       "3                    0                   0  \n",
       "4                    1                   1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               bmi|\n",
      "+-------+------------------+\n",
      "|  count|             68056|\n",
      "|   mean|27.313671829080924|\n",
      "| stddev| 4.934954139584941|\n",
      "|    min|             10.73|\n",
      "|    max|             58.02|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "# Calculate BMI\n",
    "merged_df = merged_df.withColumn(\"bmi\", col(\"weight\") / ((col(\"height\") / 100) ** 2))\n",
    "\n",
    "# Round BMI to 2 decimal places\n",
    "merged_df = merged_df.withColumn(\"bmi\", round(col(\"bmi\"), 2))\n",
    "\n",
    "# Show descriptive statistics for BMI\n",
    "merged_df.describe(\"bmi\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               bmi|\n",
      "+-------+------------------+\n",
      "|  count|             68056|\n",
      "|   mean|26.348999059599507|\n",
      "| stddev| 3.571605400963905|\n",
      "|    min|              16.0|\n",
      "|    max|              35.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, percentile_approx\n",
    "\n",
    "# Calculate the median of bmi\n",
    "median_bmi = merged_df.approxQuantile(\"bmi\", [0.5], 0.0)[0]  # Using approxQuantile to get the median\n",
    "\n",
    "# Define the conditions for outliers\n",
    "condition = (col(\"bmi\") < 16) | (col(\"bmi\") > 35)\n",
    "\n",
    "# Replace outliers with the median value\n",
    "merged_df = merged_df.withColumn(\"bmi\", when(condition, median_bmi).otherwise(col(\"bmi\")))\n",
    "merged_df.describe(\"bmi\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+------+------+------+-----+-----+-----------+----+-----+----+------+------+-----+\n",
      "| id|index| age|gender|height|weight|ap_hi|ap_lo|cholesterol|gluc|smoke|alco|active|cardio|  bmi|\n",
      "+---+-----+----+------+------+------+-----+-----+-----------+----+-----+----+------+------+-----+\n",
      "|  0|    0|50.4|     2|   168|  62.0|  110|   80|          1|   1|    0|   0|     1|     0|21.97|\n",
      "|  1|    1|55.4|     1|   156|  85.0|  140|   90|          3|   1|    0|   0|     1|     1|34.93|\n",
      "|  2|    2|51.7|     1|   165|  64.0|  130|   70|          3|   1|    0|   0|     0|     1|23.51|\n",
      "|  3|    3|48.3|     2|   169|  82.0|  150|  100|          1|   1|    0|   0|     1|     1|28.71|\n",
      "|  4|    4|47.9|     1|   156|  56.0|  100|   60|          1|   1|    0|   0|     0|     0|23.01|\n",
      "|  8|    5|60.0|     1|   151|  67.0|  120|   80|          2|   2|    0|   0|     0|     0|29.38|\n",
      "|  9|    6|60.6|     1|   157|  93.0|  130|   80|          3|   1|    0|   0|     1|     0| 26.3|\n",
      "| 12|    7|61.9|     2|   178|  95.0|  130|   90|          3|   3|    0|   0|     1|     1|29.98|\n",
      "| 13|    8|48.4|     1|   158|  71.0|  110|   70|          1|   1|    0|   0|     1|     0|28.44|\n",
      "| 14|    9|54.3|     1|   164|  68.0|  110|   60|          1|   1|    0|   0|     0|     0|25.28|\n",
      "| 15|   10|61.7|     1|   169|  80.0|  120|   80|          1|   1|    0|   0|     1|     0|28.01|\n",
      "| 16|   11|51.5|     2|   173|  60.0|  120|   80|          1|   1|    0|   0|     1|     0|20.05|\n",
      "| 18|   12|40.5|     2|   165|  60.0|  120|   80|          1|   1|    0|   0|     0|     0|22.04|\n",
      "| 21|   13|54.3|     1|   158|  78.0|  110|   70|          1|   1|    0|   0|     1|     0|31.24|\n",
      "| 23|   14|39.8|     2|   181|  95.0|  130|   90|          1|   1|    1|   1|     1|     0| 29.0|\n",
      "| 24|   15|46.0|     2|   172| 112.0|  120|   80|          1|   1|    0|   0|     0|     1| 26.3|\n",
      "| 25|   16|58.3|     1|   170|  75.0|  130|   70|          1|   1|    0|   0|     0|     0|25.95|\n",
      "| 27|   17|45.9|     1|   158|  52.0|  110|   70|          1|   3|    0|   0|     1|     0|20.83|\n",
      "| 28|   18|47.9|     1|   154|  68.0|  100|   70|          1|   1|    0|   0|     0|     0|28.67|\n",
      "| 29|   19|59.6|     2|   162|  56.0|  120|   70|          1|   1|    1|   0|     1|     0|21.34|\n",
      "+---+-----+----+------+------+------+-----+-----+-----------+----+-----+----+------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "# Convert 'age' from days to years and round it to 1 decimal place\n",
    "merged_df = merged_df.withColumn(\"age\", round(col(\"age\") / 365.0, 1))\n",
    "merged_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(Sales)=400.5)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(avg(Sales)=400.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! At this stage, we're pretty much done with understanding DataFrames. You can now move on to applying an algorithm. We recommend going through linear regression, then logistic regression and finishing off with tree methods. It's best to start with the documentation example before moving to the advanced example. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
